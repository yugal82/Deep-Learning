{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4dc66b-0b64-43f7-8810-54c94e9c52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b60c4f-4849-47d4-8569-f364c528fc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>0.1609</th>\n",
       "      <th>0.1582</th>\n",
       "      <th>0.2238</th>\n",
       "      <th>0.0645</th>\n",
       "      <th>0.0660</th>\n",
       "      <th>0.2273</th>\n",
       "      <th>0.3100</th>\n",
       "      <th>0.2999</th>\n",
       "      <th>0.5078</th>\n",
       "      <th>0.4797</th>\n",
       "      <th>0.5783</th>\n",
       "      <th>0.5071</th>\n",
       "      <th>0.4328</th>\n",
       "      <th>0.5550</th>\n",
       "      <th>0.6711</th>\n",
       "      <th>0.6415</th>\n",
       "      <th>0.7104</th>\n",
       "      <th>0.8080</th>\n",
       "      <th>0.6791</th>\n",
       "      <th>0.3857</th>\n",
       "      <th>0.1307</th>\n",
       "      <th>0.2604</th>\n",
       "      <th>0.5121</th>\n",
       "      <th>0.7547</th>\n",
       "      <th>0.8537</th>\n",
       "      <th>0.8507</th>\n",
       "      <th>0.6692</th>\n",
       "      <th>0.6097</th>\n",
       "      <th>0.4943</th>\n",
       "      <th>0.2744</th>\n",
       "      <th>0.0510</th>\n",
       "      <th>0.2834</th>\n",
       "      <th>0.2825</th>\n",
       "      <th>0.4256</th>\n",
       "      <th>0.2641</th>\n",
       "      <th>0.1386</th>\n",
       "      <th>0.1051</th>\n",
       "      <th>0.1343</th>\n",
       "      <th>0.0383</th>\n",
       "      <th>0.0324</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.3785</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>0.6378</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.6906</td>\n",
       "      <td>0.8513</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.7676</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.5463</td>\n",
       "      <td>0.5515</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.3384</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.5684</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.4331</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.7138</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.5254</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.3521</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.4164</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.2484</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.3279</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.7468</td>\n",
       "      <td>0.7676</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9481</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.6008</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>0.5619</td>\n",
       "      <td>0.5141</td>\n",
       "      <td>0.6084</td>\n",
       "      <td>0.5621</td>\n",
       "      <td>0.5956</td>\n",
       "      <td>0.6078</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>0.5147</td>\n",
       "      <td>0.4372</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>0.4677</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>0.4823</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.6997</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.8633</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.3129</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.1986</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  ...  0.0072  0.0167  0.0180  0.0084  0.0090  0.0032  R\n",
       "16   0.0192  0.0607  0.0378  0.0774  0.1388  0.0809  0.0568  ...  0.0108  0.0024  0.0045  0.0037  0.0112  0.0075  R\n",
       "62   0.0067  0.0096  0.0024  0.0058  0.0197  0.0618  0.0432  ...  0.0040  0.0019  0.0034  0.0034  0.0051  0.0031  R\n",
       "146  0.0654  0.0649  0.0737  0.1132  0.2482  0.1257  0.1797  ...  0.0447  0.0394  0.0355  0.0440  0.0243  0.0098  M\n",
       "48   0.0119  0.0582  0.0623  0.0600  0.1397  0.1883  0.1422  ...  0.0123  0.0069  0.0076  0.0073  0.0030  0.0138  R\n",
       "123  0.0388  0.0324  0.0688  0.0898  0.1267  0.1515  0.2134  ...  0.0079  0.0111  0.0107  0.0068  0.0097  0.0067  M\n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Datasets/sonar_dataset.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0524b6da-94e9-4874-bf49-4b559af679eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a854ce6-1e2b-4ec7-87c4-082a1937451a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0200    0\n",
       "0.0371    0\n",
       "0.0428    0\n",
       "0.0207    0\n",
       "0.0954    0\n",
       "         ..\n",
       "0.0180    0\n",
       "0.0084    0\n",
       "0.0090    0\n",
       "0.0032    0\n",
       "R         0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d562e504-5856-47ca-8b4c-58380e957f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "M    111\n",
       "R     96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['R'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "260a8107-d2ca-42c3-ad7b-80ab737d217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('R', axis='columns')\n",
    "y = df['R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "626c6c7c-443d-4165-832f-7e0002e3682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "65   1\n",
       "149  0\n",
       "104  0\n",
       "126  0\n",
       "116  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y, dtype=int, drop_first=True)\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a06cb51-c35e-44f2-b547-49b34cb4bfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "0    111\n",
       "1     96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f73c70-d55c-4113-aa32-b40f1fc404d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aed43840-4f20-4c0f-83ff-64b6734097af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6257ebd-6fb2-4208-94d7-d82a09c5fa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 4ms/step - loss: 0.6990 - accuracy: 0.5097\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5613\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.5871\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6323\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7613\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7419\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7806\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.8323\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7290\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8129\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8452\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8645\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8774\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8258\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8581\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8839\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8710\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.8968\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.9097\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8710\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.8968\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8581\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.8645\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.9161\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9419\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9226\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1981 - accuracy: 0.9290\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.9355\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9290\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9548\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9484\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1568 - accuracy: 0.9355\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9742\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9742\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9677\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9742\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9871\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9419\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9806\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9742\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9871\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9871\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9871\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9935\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9871\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9806\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9613\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9871\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9935\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9871\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9871\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9935\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9871\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9935\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9935\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x263d69fa380>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4e405c0-718f-4e08-90d3-40b507e4bbb1",
   "metadata": {},
   "source": [
    "The above model's accuracy is 100% which tends to overfit the training data. However, it does not perform with the same accuracy on test data.\n",
    "We will train the above model with dropout regularization below (after few cells) to overcome overfitting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd63e825-0a98-40ed-8794-ea42768c3f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6727 - accuracy: 0.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6727158427238464, 0.8461538553237915]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5656a9c4-849a-4400-857c-3f11b47559ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "[1.5625553e-04 1.8974502e-05 3.4555826e-02 3.1044090e-04 9.9999654e-01\n",
      " 1.0989471e-02 9.6433491e-01 2.9815026e-04 2.1451537e-04 9.9999934e-01]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to the nearest integer i.e 1 or 0\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c35ce27-af3e-4b06-b1f1-906198c5e78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "186  0\n",
       "155  0\n",
       "165  0\n",
       "200  0\n",
       "58   1\n",
       "34   1\n",
       "151  0\n",
       "18   1\n",
       "202  0\n",
       "62   1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85d1dcf2-f5ee-47ac-9208-7a4cbc342470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86        27\n",
      "           1       0.90      0.76      0.83        25\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.86      0.84      0.84        52\n",
      "weighted avg       0.85      0.85      0.84        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dea759bd-31d4-4f23-9654-6ddf6a35b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 4ms/step - loss: 0.6972 - accuracy: 0.4903\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5548\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.5548\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.5032\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5613\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.5290\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.5871\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5419\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.5742\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6194\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6516\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.5806\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6452\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6645\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6194\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6581\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7290\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.6968\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7161\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7161\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7290\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7548\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7226\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7161\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5041 - accuracy: 0.7935\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7290\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7484\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7871\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7935\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.6903\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7935\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7419\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8065\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8194\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.8194\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7871\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8258\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8065\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7935\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.8065\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7871\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8194\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8581\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8581\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8129\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8194\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8323\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8516\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8258\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8452\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8258\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8774\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8387\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8323\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8516\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8516\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8774\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8516\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8581\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8968\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.8839\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8387\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8452\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8645\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8452\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8839\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8645\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8516\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8452\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8968\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9226\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8774\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.8839\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8839\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9161\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.9032\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8581\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8903\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.9032\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.8968\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9097\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2270 - accuracy: 0.8968\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.9097\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8839\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.8903\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9097\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8581\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8710\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.8903\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2421 - accuracy: 0.8839\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9419\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.8903\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.9161\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9032\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2297 - accuracy: 0.9161\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x263d55d20b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6f146d0-20cf-4d50-b5d7-743526a4fe2a",
   "metadata": {},
   "source": [
    "Here, the accuracy of the same Neural Network with Dropout layer reduces the accuracy of the model. This overcomes the problem of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c72aedc0-8899-4cc7-846a-658550cc3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4638 - accuracy: 0.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4637952148914337, 0.8461538553237915]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd176d1-0f7d-461d-b5ac-a738c3fea49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
